{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8f8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================功能性函数=======================================================\n",
    "def create_data(day,node_set,LMP_data):#取出每天的电价\n",
    "    dict_LMP={}\n",
    "    for i in node_set:\n",
    "        dict_LMP[i]=LMP_data[i][day]\n",
    "    return dict_LMP\n",
    "\n",
    "def Distance(s1, s2):\n",
    "    return sqrt(sum((s1-s2)**2))\n",
    "\n",
    "def dist(node1,node2,para,dict_LMP):#计算两个点之间的时空距离\n",
    "    return Distance(dict_LMP[node1],dict_LMP[node2])*(duration[node_set.index(node1)][node_set.index(node2)]**0.5)\n",
    "\n",
    "def sel_center(node_list,dict_LMP,para):#选取中心点\n",
    "    list2=[]\n",
    "    for i in node_list:\n",
    "        list2.append((i,sum([dist(i,j,para,dict_LMP) for j in node_list])))\n",
    "    list2=sorted(list2,key=lambda x: x[1])\n",
    "    return list2[0][0]\n",
    "\n",
    "def k_means(node_set,k,para,dict_LMP):\n",
    "    core_list=[]\n",
    "    new_core=random.sample(node_set,k)\n",
    "    t=1\n",
    "    while set(new_core)!=set(core_list) and t<100:\n",
    "        t+=1\n",
    "        core_list=new_core\n",
    "        new_core=[]\n",
    "        clf_list=[]\n",
    "        for i in range(k):\n",
    "            clf_list.append([core_list[i]])      \n",
    "        for i in node_set:\n",
    "            list1=[]\n",
    "            for j in range(len(core_list)):\n",
    "                list1.append((j,dist(i,core_list[j],para,dict_LMP)))\n",
    "            list1=sorted(list1,key=lambda x: x[1])\n",
    "            clf_list[list1[0][0]].append(i)\n",
    "        clf_list=[list(set(i)) for i in clf_list]\n",
    "        for i in clf_list:\n",
    "            new_core.append(sel_center(i,dict_LMP,para))\n",
    "    return core_list,clf_list\n",
    "#========================================================聚类函数================================================================\n",
    "'''\n",
    "def cluster(node_set,LMP_data,para,day,k):\n",
    "    dict_LMP=create_data(day,node_set,LMP_data)\n",
    "    core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "    out_list=[]\n",
    "    for i in range(k):\n",
    "        df_empty = pd.DataFrame(columns=clf_list[i])\n",
    "        list1=[]\n",
    "        list2=[]\n",
    "        for nods in clf_list[i]:\n",
    "            df_empty[nods]=dict_LMP[nods]\n",
    "        df_mean=np.array(df_empty.mean()).mean()\n",
    "        for j in range(24):\n",
    "            array1=np.array(df_empty.iloc[j,:])\n",
    "            array1=array1-df_mean\n",
    "            index_max=list(abs(array1)).index(max(abs(array1)))\n",
    "            list1.append(df_empty.columns[index_max])\n",
    "            list2.append(array1[index_max]+df_mean)\n",
    "        out_list.append(max(list1,key=list1.count))\n",
    "    return out_list\n",
    "'''\n",
    "#第一种构造虚拟电价的方法，只考虑当天同一个聚类情况下的点。这个地方的days可以是一个含有很多日期的列表。\n",
    "def add_max_difference_column(dataframe):\n",
    "    mean_values = dataframe.mean(axis=1)\n",
    "    differences = dataframe.sub(mean_values, axis=0).abs()\n",
    "    max_difference_column = differences.idxmax(axis=1)\n",
    "    dataframe['Max_Difference'] = dataframe.apply(lambda row: row[max_difference_column[row.name]], axis=1)\n",
    "    dataframe['Name'] = max_difference_column\n",
    "    return dataframe\n",
    "\n",
    "def cluster_1(node_set,LMP_data,para,days,k):\n",
    "    out_dict={}\n",
    "    for day in days:\n",
    "        dict_LMP=create_data(day,node_set,LMP_data)\n",
    "        core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "        sumofdist=0\n",
    "        for i in range(k):\n",
    "            sumofdist+=sum([dist(core_list[i],t,1,dict_LMP) for t in clf_list[i]])\n",
    "        tmp_dict={}\n",
    "        for i in range(k):\n",
    "            df_empty = pd.DataFrame(columns=clf_list[i])\n",
    "            list1=[]\n",
    "            list2=[]\n",
    "            for nods in clf_list[i]:\n",
    "                df_empty[nods]=dict_LMP[nods]\n",
    "            df_empty=add_max_difference_column(df_empty)\n",
    "            fake_price = copy.deepcopy(df_empty[[core_list[i],'Max_Difference','Name']])\n",
    "            tmp_dict[core_list[i]] = fake_price\n",
    "        out_dict[day]=tmp_dict\n",
    "    \n",
    "    return out_dict,sumofdist\n",
    "\n",
    "def cluster_2(node_set,LMP_data,para,days,k):#在cluster1上的改进，聚类能够更加紧密。\n",
    "    out_dict={}\n",
    "    for day in days:\n",
    "        dict_LMP=create_data(day,node_set,LMP_data)\n",
    "        sort_list=[]\n",
    "        for i in range(10):\n",
    "            core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "            sumofdist=0\n",
    "            for i in range(k):\n",
    "                sumofdist+=sum([dist(core_list[i],t,1,dict_LMP) for t in clf_list[i]])\n",
    "            sort_list.append((core_list,clf_list,sumofdist))\n",
    "        sorted_list = sorted(sort_list, key=lambda x: x[-1])\n",
    "        core_list,clf_list,sumofdist = sorted_list[0]\n",
    "        tmp_dict={}\n",
    "        for i in range(k):\n",
    "            df_empty = pd.DataFrame(columns=clf_list[i])\n",
    "            list1=[]\n",
    "            list2=[]\n",
    "            for nods in clf_list[i]:\n",
    "                df_empty[nods]=dict_LMP[nods]\n",
    "            df_empty=add_max_difference_column(df_empty)\n",
    "            fake_price = copy.deepcopy(df_empty[[core_list[i],'Max_Difference','Name']])\n",
    "            tmp_dict[core_list[i]] = fake_price\n",
    "        out_dict[day]=tmp_dict\n",
    "    \n",
    "    return out_dict,sumofdist\n",
    "'''\n",
    "def cluster_test(node_set,LMP_data,para,days,k):#只做聚类不计算\n",
    "    out_dict={}\n",
    "    for day in days:\n",
    "        dict_LMP=create_data(day,node_set,LMP_data)\n",
    "        sort_list=[]\n",
    "        for i in range(10):\n",
    "            core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "            sumofdist=0\n",
    "            for i in range(k):\n",
    "                sumofdist+=sum([dist(core_list[i],t,1,dict_LMP) for t in clf_list[i]])\n",
    "            sort_list.append((core_list,clf_list,sumofdist))\n",
    "        sorted_list = sorted(sort_list, key=lambda x: x[-1])\n",
    "        core_list,clf_list,sumofdist = sorted_list[0]\n",
    "        return sumofdist\n",
    "'''\n",
    "#第三种聚类方法，部分地实现自适应，在给定聚类中心数并获得out_dict后，根据out_dict的特性决定是不是需要将其中的某个聚类分裂成两个\n",
    "#修改alter函数或者生成out_dict的函数，不能使用聚类中心的地理坐标，而是应该使用那些被访问最多的点。\n",
    "from collections import Counter\n",
    "def sel_node(out_dict):#这个函数将保证out_dict中的每一个聚类所取的地理位置都更加合适\n",
    "    new_dict = dict()\n",
    "    for days in out_dict:\n",
    "        original_day_dict = out_dict[days]\n",
    "        new_day_dict=dict()\n",
    "        for nodes in original_day_dict:\n",
    "            temp_list = list(original_day_dict[nodes]['Name'])\n",
    "            counter = Counter(temp_list)\n",
    "            geo_node = counter.most_common(1)[0][0]\n",
    "            new_day_dict[geo_node] = original_day_dict[nodes]\n",
    "        new_dict[days] = new_day_dict\n",
    "    \n",
    "    return new_dict\n",
    "def cluster_3(node_set,LMP_data,para,days,k):#在cluster2上的改进\n",
    "    out_dict={}\n",
    "    for day in days:\n",
    "        dict_LMP=create_data(day,node_set,LMP_data)\n",
    "        sort_list=[]\n",
    "        for i in range(10):\n",
    "            core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "            sumofdist=0\n",
    "            for i in range(k):\n",
    "                sumofdist+=sum([dist(core_list[i],t,1,dict_LMP) for t in clf_list[i]])\n",
    "            sort_list.append((core_list,clf_list,sumofdist))\n",
    "        sorted_list = sorted(sort_list, key=lambda x: x[-1])\n",
    "        core_list,clf_list,sumofdist = sorted_list[0]\n",
    "        tmp_dict={}\n",
    "        for i in range(k):\n",
    "            df_empty = pd.DataFrame(columns=clf_list[i])\n",
    "            list1=[]\n",
    "            list2=[]\n",
    "            for nods in clf_list[i]:\n",
    "                df_empty[nods]=dict_LMP[nods]\n",
    "            df_empty=add_max_difference_column(df_empty)\n",
    "            fake_price = copy.deepcopy(df_empty[[core_list[i],'Max_Difference','Name']])\n",
    "            tmp_dict[core_list[i]] = fake_price\n",
    "        \n",
    "        \n",
    "        out_dict[day]=tmp_dict\n",
    "        out_dict = sel_node(out_dict)\n",
    "    return out_dict,sumofdist\n",
    "\n",
    "def cluster_4(node_set,LMP_data,para,days,k):#在cluster3上的改进,实现自适应的聚类,此处k为下限\n",
    "    out_dict={}\n",
    "    for day in days:\n",
    "        dict_LMP=create_data(day,node_set,LMP_data)\n",
    "        Dataframe_LMP = pd.DataFrame(dict_LMP)\n",
    "        sort_list=[]\n",
    "        for i in range(10):\n",
    "            core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "            sumofdist=0\n",
    "            for i in range(k):\n",
    "                sumofdist+=sum([dist(core_list[i],t,1,dict_LMP) for t in clf_list[i]])\n",
    "            sort_list.append((core_list,clf_list,sumofdist))\n",
    "        sorted_list = sorted(sort_list, key=lambda x: x[-1])\n",
    "        core_list,clf_list,sumofdist = sorted_list[0]\n",
    "        def gen_tmp_dict(clf_list,core_list,dict_LMP):\n",
    "            k = len(clf_list)\n",
    "            tmp_dict={}\n",
    "            for i in range(k):\n",
    "                df_empty = pd.DataFrame(columns=clf_list[i])\n",
    "                list1=[]\n",
    "                list2=[]\n",
    "                for nods in clf_list[i]:\n",
    "                    df_empty[nods]=dict_LMP[nods]\n",
    "                df_empty=add_max_difference_column(df_empty)\n",
    "                fake_price = copy.deepcopy(df_empty[[core_list[i],'Max_Difference','Name']])\n",
    "                tmp_dict[core_list[i]] = fake_price\n",
    "            return tmp_dict\n",
    "        tmp_dict = gen_tmp_dict(clf_list,core_list,dict_LMP)\n",
    "        #此处已经形成了一个tmp_dict，还有core_list,clf_list,接下来的问题是如何自适应地不断更新clf_list\n",
    "        signal = 1\n",
    "        while signal == 1:\n",
    "            keys_list = list(tmp_dict.keys())\n",
    "            signal_list = [0]*len(keys_list)#用来表示每一个聚类是否被修改，最后只有当全部为0时才把signal置0\n",
    "            for i in range(len(signal_list)):\n",
    "                cluster_data = tmp_dict[keys_list[i]]\n",
    "                #先挑出最多的那个点代表肯定要\n",
    "                list1 = list(cluster_data['Name'])\n",
    "                counter = Counter(list1)\n",
    "                geo_node = counter.most_common(1)[0][0]\n",
    "                for j in range(23):\n",
    "                    if list1[j]!=geo_node and (cluster_data['Max_Difference'][j] == sorted(list(Dataframe_LMP.iloc[j]))[0] or cluster_data['Max_Difference'][j] == sorted(list(Dataframe_LMP.iloc[j]))[1] or cluster_data['Max_Difference'][j] == sorted(list(Dataframe_LMP.iloc[j]))[-1] or cluster_data['Max_Difference'][j] == sorted(list(Dataframe_LMP.iloc[j]))[-2]):\n",
    "                        signal_list[i]=1\n",
    "                        #print(i)\n",
    "                        #print(clf_list[i])\n",
    "                        clf_list[i].remove(list1[j])\n",
    "                        clf_list.append([list1[j]])\n",
    "                        break\n",
    "            if sum(signal_list)==0:\n",
    "                signal = 0\n",
    "            core_list = [t[0] for t in clf_list]\n",
    "            tmp_dict = gen_tmp_dict(clf_list,core_list,dict_LMP)\n",
    "                                                                   \n",
    "        out_dict[day]=tmp_dict\n",
    "        out_dict = sel_node(out_dict)\n",
    "    return clf_list,out_dict,sumofdist\n",
    "\n",
    "def cluster_4_1(node_set,LMP_data,para,days,k):#在cluster3上的改进,实现自适应的聚类,此处k为下限\n",
    "    out_dict={}\n",
    "    for day in days:\n",
    "        dict_LMP=create_data(day,node_set,LMP_data)\n",
    "        Dataframe_LMP = pd.DataFrame(dict_LMP)\n",
    "        sort_list=[]\n",
    "        for i in range(10):\n",
    "            core_list,clf_list=k_means(node_set,k,para,dict_LMP)\n",
    "            sumofdist=0\n",
    "            for i in range(k):\n",
    "                sumofdist+=sum([dist(core_list[i],t,1,dict_LMP) for t in clf_list[i]])\n",
    "            sort_list.append((core_list,clf_list,sumofdist))\n",
    "        sorted_list = sorted(sort_list, key=lambda x: x[-1])\n",
    "        core_list,clf_list,sumofdist = sorted_list[0]\n",
    "        def gen_tmp_dict(clf_list,core_list,dict_LMP):\n",
    "            k = len(clf_list)\n",
    "            tmp_dict={}\n",
    "            for i in range(k):\n",
    "                df_empty = pd.DataFrame(columns=clf_list[i])\n",
    "                list1=[]\n",
    "                list2=[]\n",
    "                for nods in clf_list[i]:\n",
    "                    df_empty[nods]=dict_LMP[nods]\n",
    "                df_empty=add_max_difference_column(df_empty)\n",
    "                fake_price = copy.deepcopy(df_empty[[core_list[i],'Max_Difference','Name']])\n",
    "                tmp_dict[core_list[i]] = fake_price\n",
    "            return tmp_dict\n",
    "        tmp_dict = gen_tmp_dict(clf_list,core_list,dict_LMP)\n",
    "        #此处已经形成了一个tmp_dict，还有core_list,clf_list,接下来的问题是如何自适应地不断更新clf_list\n",
    "        signal = 1\n",
    "        while signal == 1:\n",
    "            keys_list = list(tmp_dict.keys())\n",
    "            signal_list = [0]*len(keys_list)#用来表示每一个聚类是否被修改，最后只有当全部为0时才把signal置0\n",
    "            for i in range(len(signal_list)):\n",
    "                cluster_data = tmp_dict[keys_list[i]]\n",
    "                #先挑出最多的那个点代表肯定要\n",
    "                list1 = list(cluster_data['Name'])\n",
    "                counter = Counter(list1)\n",
    "                geo_node = counter.most_common(1)[0][0]\n",
    "                for j in range(23):\n",
    "                    if list1[j]!=geo_node and (cluster_data['Max_Difference'][j] == sorted(list(Dataframe_LMP.iloc[j]))[0] or cluster_data['Max_Difference'][j] == sorted(list(Dataframe_LMP.iloc[j]))[-1]):\n",
    "                        signal_list[i]=1\n",
    "                        #print(i)\n",
    "                        #print(clf_list[i])\n",
    "                        clf_list[i].remove(list1[j])\n",
    "                        clf_list.append([list1[j]])\n",
    "                        break\n",
    "            if sum(signal_list)==0:\n",
    "                signal = 0\n",
    "            core_list = [t[0] for t in clf_list]\n",
    "            tmp_dict = gen_tmp_dict(clf_list,core_list,dict_LMP)\n",
    "                                                                   \n",
    "        out_dict[day]=tmp_dict\n",
    "        out_dict = sel_node(out_dict)\n",
    "    return clf_list,out_dict,sumofdist\n",
    "\n",
    "#如果out_dict中的点为当前时间最大或者最小的电价，则为其单开一列\n",
    "from itertools import chain\n",
    "def cluster_5(node_set,LMP_data,para,days,k,signal):#希望返回一个这样的字典{day1：【clf_list1】,...}\n",
    "    clflist_dict={}\n",
    "    for day in days:\n",
    "        key_set = set()\n",
    "        for i in range(10):\n",
    "            if signal==1:\n",
    "                clf_list,out_dict, sumofdist = cluster_4_1(node_set, LMP_data, 1, [day], k)\n",
    "            elif signal==0:\n",
    "                clf_list,out_dict, sumofdist = cluster_4(node_set, LMP_data, 1, [day], k)       \n",
    "            keys = out_dict[day].keys()\n",
    "            key_set.update(keys)\n",
    "        clflist_dict[day] = list(key_set)\n",
    "    return clflist_dict\n",
    "\n",
    "#===========================================================聚类后的调整与利润计算============================================================\n",
    "import copy \n",
    "def alter(out_dict,LMP_data):#out_dict中存放的字典实例{81{node1：}}\n",
    "    #为了防止基础的LMP_data被改变\n",
    "    copy_LMP = copy.deepcopy(LMP_data)\n",
    "    days=list(out_dict.keys())\n",
    "    for i in days:\n",
    "        tmp_dict=out_dict[i]\n",
    "        for node in tmp_dict.keys():\n",
    "            copy_LMP[node][i]=np.array(tmp_dict[node]['Max_Difference'])\n",
    "    return copy_LMP\n",
    "\n",
    "def cal_pro(df):\n",
    "    pro=0\n",
    "    list1=list(df.columns)\n",
    "    for i in range(len(list1)//2):\n",
    "        pro = pro+sum(np.array(df[list1[i]])*np.array(df[list1[i+len(list1)//2]]))\n",
    "    return pro\n",
    "\n",
    "def chg_outdict(out_dict,node_set,duration):\n",
    "    #第一步应该是计算相关参数，但是因为多天非常难操作先考虑单天，故将一大堆东西省略\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for day in list(out_dict.keys()):\n",
    "        day_dict=out_dict[day]\n",
    "        out_set=list(out_dict[day].keys())\n",
    "        [duration_1,distance] = travel_data_cal(out_set,node_data)\n",
    "        dataframe=get_Dataframe(duration_1,out_set,day,day_dict)\n",
    "        list1.append('第'+str(day)+'天在删除不可能路径前的利润为'+str(cal_pro(dataframe)))\n",
    "        list2.append(cal_pro(dataframe))\n",
    "        dataframe=chg(duration,node_set,duration_1,out_set,day_dict,dataframe)\n",
    "        list1.append('第'+str(day)+'天删除不可能路径后的利润为'+str(cal_pro(dataframe)))\n",
    "        list2.append(cal_pro(dataframe))\n",
    "    return list1,list2\n",
    "    \n",
    "        \n",
    "def get_Dataframe(duration_1,out_set,day,day_dict):\n",
    "    day_set=[day]\n",
    "    g_dict={}\n",
    "\n",
    "    g_dict[day]=day_dict\n",
    "    [model2,sta_profit,sta_usage,sta_profit_reserve,elapsed_time2,G2,PESS_cha,PESS_dis,SESS_energy,PESS_energy,RES_cap,record_PESS_cha_dis,PESS_REP_travel_grid,PESS_travel_grid] = data_driven_model_solve(u,mcu,c_tr,num_veh,day_set,scale,out_set,duration_1,AS_type,alter(g_dict,LMP_data),price_data_SR,price_data_NR,save_dir,power_cap,energy_cap,effi,n,SOH,solver_option,timelimit,save_file_flag,c_index,print_log,rep_log,price_differ,RT_flag)\n",
    "    new_value = np.zeros(shape = (num_veh,len(PESS_travel_grid[0][0]),96))\n",
    "    for ii in range(1,num_veh+1):\n",
    "        for i in range(0,len(PESS_travel_grid[ii-1][0])):\n",
    "            for j in range(0,96):\n",
    "                new_value[ii-1][i][j] = round(model2.energy_veh_discharged['v'+str(ii),PESS_travel_grid[ii-1][0][i],j].value,4) -round(model2.energy_veh_charged['v'+str(ii),PESS_travel_grid[ii-1][0][i],j].value,4)\n",
    "        dataframe1 = pd.DataFrame({'Energy at Node ' + str(PESS_travel_grid[ii-1][0][node_id]): new_value[ii-1][node_id] for node_id in range(0,len(new_value[ii-1]))})\n",
    "        dataframe2 = pd.DataFrame({'LMP at Node ' + str(PESS_travel_grid[ii-1][0][node_id]): model2.price[PESS_travel_grid[ii-1][0][node_id]] for node_id in range(0,len(new_value[ii-1]))})\n",
    "        dataframe =pd.concat([dataframe1, dataframe2], axis=1, join='inner')\n",
    "        return dataframe\n",
    "\n",
    "def chg(duration,node_set,duration_1,out_set,day_dict,dataframe):\n",
    "    #第一步，把day_dict的格式规范化为96行的\n",
    "    for node in day_dict.keys():\n",
    "        tmpdf = day_dict[node]\n",
    "        tmpdf = pd.DataFrame(np.repeat(tmpdf.values,4,axis=0), columns=tmpdf.columns)\n",
    "        day_dict[node] = tmpdf\n",
    "    #第二步，整理出一条小车的路径\n",
    "    dataframe_half = dataframe.iloc[:, :len(list(dataframe.columns))//2]\n",
    "    lst=[]\n",
    "    for i in list(dataframe_half.columns):\n",
    "        num = int(i[-1])-1\n",
    "        node = list(day_dict.keys())[num]\n",
    "        rout_lst = list(day_dict[node]['Name'])\n",
    "        sig_lst = list(dataframe_half[i])        \n",
    "        result_list = [rout_lst[j] if sig_lst[j]!=0 else 0 for j in range(len(rout_lst))]\n",
    "        lst.append(result_list)\n",
    "    route_list = [next((item for item in items if item != 0), 0) for items in zip(*lst)]\n",
    "    #第三步，修改route_list\n",
    "    def interval(node_1,node_2,duration,node_set):\n",
    "        index_1 = node_set.index(node_1)\n",
    "        index_2 = node_set.index(node_2)\n",
    "        return duration[index_1][index_2]        \n",
    "    last_non_zero = None\n",
    "    for i in range(len(route_list)):\n",
    "        if route_list[i] != 0:  # If element is not 0\n",
    "            if last_non_zero is None:\n",
    "                last_non_zero = i\n",
    "            elif last_non_zero is not None:  # If there was a non zero element before it\n",
    "                if interval(route_list[i],route_list[last_non_zero],duration,node_set)<=15*(i-last_non_zero-1):\n",
    "                    last_non_zero = i\n",
    "                elif interval(route_list[i],route_list[last_non_zero],duration,node_set)>15*(i-last_non_zero-1):\n",
    "                    route_list[i]=0\n",
    "    #第四步修改dataframe\n",
    "    signal_list = [1 if i != 0 else 0 for i in route_list]\n",
    "    for i in list(dataframe_half.columns):\n",
    "        dataframe[i] = np.array(dataframe[i])*np.array(signal_list)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import requests, zipfile, io\n",
    "import pytz, datetime\n",
    "from io import BytesIO\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os, sys\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from pyomo.environ import *\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cloudpickle\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "start_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print('Current time:',start_time)\n",
    "%set_env GUROBI_HOME=/usr/local/gurobi/gurobi951/linux64\n",
    "    \n",
    "# from sta.bat_sta import *\n",
    "from sta.traffic_data_fetch import *\n",
    "from sta.load_data import *\n",
    "# from sta.load_node_set import *\n",
    "from sta.node_data_processing import *\n",
    "from sta.node_distance_cal import *\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "print('Functions loaded.')\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_path = cwd +'/Data/'\n",
    "results_dir = cwd+'/results/'\n",
    "save_dir = cwd+'/results/'\n",
    "\n",
    "par = pd.read_csv(data_path + \"parameter_setting.csv\")\n",
    "# node_data = pd.read_csv(data_path + \"node.csv\")\n",
    "pkl_file = open(data_path+'node_data_clean.pkl', 'rb')\n",
    "node_data = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "[location_data,node_id_set,duration_data,distance_data,LMP_data,LMP_data_RTM,price_data_SR,price_data_NR] = load_data(data_path)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "timelimit = 100\n",
    "solver_option = 0 ## 0:Gurobi, 1:CPLEX, 2:GAMS\n",
    "radius = 7\n",
    "\n",
    "total_node_num = len(node_data)\n",
    "\n",
    "sample_node_set = [36]\n",
    "\n",
    "\n",
    "for sample_number in sample_node_set:\n",
    "    # for c in idx:\n",
    "    c_index = int(sample_number)\n",
    "    print('Task ID:', c_index)\n",
    "    center_node_name = node_data['node_name'][c_index]\n",
    "    print('Center Node:', center_node_name)\n",
    "    print('Radius:', radius)\n",
    "    print('Timelimit:', timelimit)\n",
    "\n",
    "    ## Inputs\n",
    "    u_min = par['u_min'][0]\n",
    "    u_max = par['u_max'][0]\n",
    "    u_scale = par['u_scale'][0]\n",
    "\n",
    "    u_sensi = par['u_sensi'][0]\n",
    "\n",
    "    AS_type = par['AS_type'][0]\n",
    "    RT_flag = par['RT_flag'][0]\n",
    "    day_num = par['day_num'][0]\n",
    "    full_day_set = np.arange(day_num)\n",
    "\n",
    "    scale = par['scale'][0]\n",
    "    energy_cap = par['energy_cap'][0]\n",
    "    power_cap = par['power_cap'][0]\n",
    "    # power_cap = 0\n",
    "    # energy_cap = 0\n",
    "    effi = par['effi'][0]\n",
    "    discount_rate = par['discount_rate'][0]\n",
    "    mcu = par['mcu'][0]\n",
    "    calendar_degradation = par['calendar_degradation'][0]\n",
    "    usage_limit = par['cycle_life'][0]*energy_cap*2*day_num/365\n",
    "    c_tr = par['c_tr'][0]*scale\n",
    "\n",
    "    save_file_flag = 1\n",
    "\n",
    "    set_region_range = 0\n",
    "    \n",
    "    if set_region_range == 0:\n",
    "        center_node = center_node_name\n",
    "\n",
    "        node_set = load_node_set_circle(center_node,radius,node_data)\n",
    "    elif set_region_range == 1:\n",
    "\n",
    "        node_set = ['KETTLEMN_6_N001','HURON_6_N001']\n",
    "\n",
    "    for cent_node in range(len(node_set)):\n",
    "        if node_set[cent_node] == 'KEARNEY_7_N001':    \n",
    "            Grid2 = cent_node\n",
    "    \n",
    "    print('Node Set loaded.')\n",
    "    node_num = len(node_set)\n",
    "    print('Number of nodes:', node_num)\n",
    "    print('SESS Node: ',node_set[Grid2])\n",
    "\n",
    "\n",
    "    [duration,distance] = travel_data_cal(node_set,node_data)\n",
    "\n",
    "\n",
    "def data_driven_model_solve(u,mcu,c_tr,num_veh,day_set,scale,node_set,duration,AS_type,\n",
    "                LMP_data,price_data_SR,price_data_NR,\n",
    "                save_dir,power_cap,energy_cap,effi,year_num,SOH,\n",
    "                solver_option,timelimit,save_file_flag,c_index,print_log,rep_log,price_differ):\n",
    "\n",
    "\n",
    "\n",
    "    node_num = len(node_set)\n",
    "    sta_profit = []\n",
    "    sta_usage = []\n",
    "    sta_reserve_rev = []\n",
    "    elapsed_time2 = []\n",
    "\n",
    "    initial_location = [0] * node_num\n",
    "    initial_location[0] = 1\n",
    "\n",
    "    for day in day_set:\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        p_da = []\n",
    "\n",
    "        for i in range(len(node_set)):\n",
    "            p_da.append(LMP_data[node_set[i]][day])\n",
    "       \n",
    "        \n",
    "        if AS_type == 'SR':\n",
    "            p_reserve = price_data_SR[day]\n",
    "        else:\n",
    "            p_reserve = price_data_NR[day] \n",
    "\n",
    "        hour_num = len(p_da[0])\n",
    "\n",
    "        model = ConcreteModel()\n",
    "        model.max_power = power_cap * scale \n",
    "        model.max_energy = energy_cap \n",
    "        model.max_interval_energy = power_cap * scale \n",
    "        model.max_vehicle_energy = energy_cap  \n",
    "        model.eta=effi\n",
    "\n",
    "        horizon = model.horizon = int(hour_num/scale)\n",
    "        model.node_num = node_num\n",
    "\n",
    "        p_da_rescale = np.zeros(shape=(len(node_set),horizon))\n",
    "        p_reserve_rescale = np.zeros(horizon)\n",
    "        for n in range(node_num):\n",
    "            for t in range(horizon):\n",
    "                p_da_rescale[n][t] = p_da[n][floor(t*scale)]  \n",
    "                p_reserve_rescale[t] = p_reserve[floor(t*scale)]\n",
    "\n",
    "        model.h = scale\n",
    "        model.Hrzn = RangeSet(0,model.horizon-1)\n",
    "        Grid = model.Grid = ['n'+str(x) for x in range(1,model.node_num+1)]\n",
    "\n",
    "        keys = Grid\n",
    "        values = p_da_rescale\n",
    "        model.price = dict(zip(keys, values)) \n",
    "        model.price_reserve = p_reserve_rescale   \n",
    "\n",
    "        if type(duration) == dict:\n",
    "            travel_time = np.ceil(duration[day]/(60*scale))\n",
    "        else:\n",
    "            travel_time = np.ceil(duration/(60*scale))\n",
    "        travel_time = travel_time.astype(int)\n",
    "\n",
    "        model.travel_time = dict(zip(keys,[dict(zip(keys, values)) for values in travel_time]))\n",
    "\n",
    "\n",
    "        model.c = mcu \n",
    "        model.c_tr = c_tr \n",
    "        model.usage_limit = model.max_interval_energy / scale * 2400\n",
    "        model.calendar_d = 0  \n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        G.add_node('source', grid=None, time=0)\n",
    "        G.add_node('sink', grid=None, time=model.horizon) # the source and sink node are added for convenience\n",
    "        # node_set = set(['source','sink'])\n",
    "        for t in range(0, model.horizon):\n",
    "            for grid_name in Grid:\n",
    "                G.add_node('%s_%d' % (grid_name, t), grid=grid_name, time=t)\n",
    "\n",
    "        # node_set.update('%s_%d' % (grid_name, t) for grid_name in Grid  for t in range(0, model.horizon))\n",
    "\n",
    "        # suppose we start from grid 1, change Grid[0] if starting from a different grid\n",
    "        G.add_edge('source', '%s_%d' % (Grid[0], 0), arc_type='entering', cost= 0)   \n",
    "        for t1 in range(0, model.horizon):  \n",
    "            for grid1_name in Grid:   #弧的起点\n",
    "                cur_grid = '%s_%d' % (grid1_name,t1)\n",
    "                for grid2_name in Grid:  #弧的终点\n",
    "                    if grid2_name==grid1_name:\n",
    "                        t2 = t1 + 1\n",
    "                    else:\n",
    "                        t2 = t1 + model.travel_time[grid1_name][grid2_name] +1\n",
    "                        \n",
    "                        if t2 < model.horizon:  \n",
    "                            if abs(model.price[grid1_name][t1]-model.price[grid2_name][t2])<price_differ:  \n",
    "                                continue\n",
    "                    if t2 >= model.horizon:\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    target_grid = '%s_%d' % (grid2_name,t2) \n",
    "                    G.add_edge(cur_grid, target_grid, arc_type='inter', \n",
    "                        cost=model.travel_time[grid1_name][grid2_name]*model.c_tr*model.h) \n",
    "\n",
    "        for grid1_name in Grid:  \n",
    "            G.add_edge('%s_%d' % (grid1_name, model.horizon-1), 'sink', arc_type='leaving', cost= 0) \n",
    "        for t in range(0, model.horizon):\n",
    "            for grid_name in Grid:\n",
    "                node_name = '%s_%d' % (grid_name, t)\n",
    "                if len(G.out_edges(node_name)) == 0 and len(G.in_edges(node_name)) == 0:\n",
    "                    G.remove_node(node_name)\n",
    "        \n",
    "        veh_lmt = 3 \n",
    "        veh_name = ['v'+str(x) for x in range(1,num_veh+1)]\n",
    "\n",
    "        model.profit = Var(domain=Reals)\n",
    "        model.revenue = Var(domain=Reals)\n",
    "        model.reserve_revenue = Var(domain=Reals)\n",
    "        model.cost_sto = Var(domain=Reals)\n",
    "        model.cost_tr = Var(domain=Reals)\n",
    "\n",
    "        if rep_log == 0:\n",
    "            model.x = Var(veh_name,G.edges,domain=Binary)\n",
    "            model.z = Var(veh_name,model.Grid,model.Hrzn,domain=Binary) \n",
    "            model.vehicle_energy = Var(veh_name, model.Hrzn, domain=NonNegativeReals,bounds=(0,model.max_vehicle_energy))\n",
    "            model.energy_veh_discharged = Var(veh_name,model.Grid,model.Hrzn, domain=NonNegativeReals,bounds=(0,model.max_interval_energy)) \n",
    "            model.energy_veh_charged = Var(veh_name,model.Grid,model.Hrzn, domain=NonNegativeReals,bounds=(0,model.max_interval_energy))\n",
    "\n",
    "            model.reserve_cap = Var(model.Grid,model.Hrzn, domain=NonNegativeReals,bounds=(0,model.max_interval_energy)) \n",
    "            model.usage = Var(domain=NonNegativeReals,bounds=(0,model.usage_limit))\n",
    "            \n",
    "            def obj_value(model):\n",
    "                return model.profit\n",
    "\n",
    "            def obj_function(model):   \n",
    "                return model.profit == model.revenue-model.cost_sto-model.cost_tr + model.reserve_revenue\n",
    "            model.OF = Constraint(rule=obj_function)\n",
    "\n",
    "            def revenue_cal(model):      \n",
    "                return model.revenue == sum(sum(sum((model.energy_veh_discharged[v,g,t]-model.energy_veh_charged[v,g,t])*model.price[g][t] for g in model.Grid) for t in model.Hrzn) for v in veh_name)\n",
    "            model.rev = Constraint(rule=revenue_cal)\n",
    "\n",
    "            def reserve_revenue_cal(model): \n",
    "                return model.reserve_revenue == sum(sum( model.reserve_cap[g,t] * model.price_reserve[t] for g in model.Grid) for t in model.Hrzn)\n",
    "            model.reserve_rev = Constraint(rule=reserve_revenue_cal)\n",
    "\n",
    "            def cost_storage_cal(model):  \n",
    "                return model.cost_sto == model.usage*model.c\n",
    "            model.cost_s = Constraint(rule=cost_storage_cal)\n",
    "\n",
    "            def cost_transportation_cal(model): \n",
    "                return model.cost_tr == sum(sum(model.x[v,arc]*G.edges[arc]['cost'] for arc in G.edges) for v in veh_name)\n",
    "            model.cost_t = Constraint(rule=cost_transportation_cal)\n",
    "\n",
    "            def usage(model):  \n",
    "                return model.usage == sum(sum(sum((model.energy_veh_discharged[v,g,t]+model.energy_veh_charged[v,g,t]) for g in model.Grid) for t in model.Hrzn) for v in veh_name) + model.calendar_d\n",
    "            model.power_usage = Constraint(rule=usage)\n",
    "\n",
    "            def balance(model,v,g):  #对应约束条件（1）\n",
    "                if g=='source':\n",
    "                    return sum(model.x[v,arc] for arc in G.out_edges(g))  == 1\n",
    "                elif g=='sink':\n",
    "                    return sum(model.x[v,arc] for arc in G.in_edges(g))  == 1\n",
    "                else:\n",
    "                    return sum(model.x[v,arc] for arc in G.out_edges(g)) - sum(model.x[v,arc] for arc in G.in_edges(g))  == 0\n",
    "            model.flow_balance = Constraint(veh_name, G.nodes, rule=balance)\n",
    "\n",
    "            def soc_change(model,v,t):\n",
    "                if t==0:\n",
    "                    return model.vehicle_energy[v,t] == model.vehicle_energy[v,model.horizon-1]-sum(model.energy_veh_discharged[v,g,t] for g in model.Grid)/model.eta + sum(model.energy_veh_charged[v,g,t] for g in model.Grid)*model.eta \n",
    "                else:\n",
    "                    return model.vehicle_energy[v,t] == model.vehicle_energy[v,t-1]-sum(model.energy_veh_discharged[v,g,t] for g in model.Grid)/model.eta + sum(model.energy_veh_charged[v,g,t] for g in model.Grid)*model.eta \n",
    "            model.soc = Constraint(veh_name, model.Hrzn, rule=soc_change)\n",
    "\n",
    "            def veh_dis_location(model,v,g,t): \n",
    "                return model.energy_veh_discharged[v,g,t] <= model.z[v,g,t] * model.max_interval_energy\n",
    "            model.p_dis = Constraint(veh_name, model.Grid,model.Hrzn, rule=veh_dis_location)  \n",
    "\n",
    "            def veh_cha_location(model,v,g,t): \n",
    "                return model.energy_veh_charged[v,g,t] <= model.z[v,g,t] * model.max_interval_energy    \n",
    "            model.p_cha = Constraint(veh_name, model.Grid,model.Hrzn, rule=veh_cha_location)              \n",
    "\n",
    "            def reserve_location(model,g,t):\n",
    "                return model.reserve_cap[g,t] <= sum(model.z[v,g,t] for v in veh_name) * model.max_interval_energy\n",
    "            model.p_reserve = Constraint(model.Grid,model.Hrzn, rule=reserve_location)\n",
    "\n",
    "            def storage_up(model,g,t):  \n",
    "                return model.reserve_cap[g,t] + sum((model.energy_veh_discharged[v,g,t] - model.energy_veh_charged[v,g,t]) for v in veh_name) <= model.max_interval_energy   \n",
    "            model.stor_up = Constraint(model.Grid,model.Hrzn, rule=storage_up)\n",
    "\n",
    "            def storage_down(model,g,t): \n",
    "                return model.reserve_cap[g,t] + sum((model.energy_veh_discharged[v,g,t] - model.energy_veh_charged[v,g,t]) for v in veh_name) >= -model.max_interval_energy   \n",
    "            model.stor_down = Constraint(model.Grid, model.Hrzn, rule=storage_down)        \n",
    "            \n",
    "            def storage_location(model,v,g,t): \n",
    "                g_arc = g+'_'+str(t)\n",
    "                return model.z[v,g,t] <= sum(model.x[v,arc] for arc in G.in_edges(g_arc)) \n",
    "            model.sto_location = Constraint(veh_name,model.Grid, model.Hrzn, rule=storage_location)\n",
    "\n",
    "            def veh_limit(model,g,t):  \n",
    "                return sum(model.z[v,g,t] for v in veh_name) <= veh_lmt\n",
    "            model.veh_limit = Constraint(model.Grid, model.Hrzn, rule=veh_limit)     \n",
    "\n",
    "\n",
    "        model.OBJ = Objective(rule=obj_value, sense=maximize)\n",
    "\n",
    "        success_flag = 0\n",
    "        print_error = 1\n",
    "        while success_flag == 0:                        \n",
    "            success_flag = 1                        \n",
    "            try:\n",
    "                if solver_option == 2:\n",
    "                    io_options = dict()\n",
    "                    opt = SolverFactory('gams')\n",
    "                    io_options['solver'] = 'cplex'\n",
    "                    results = opt.solve(model,tee=print_log,io_options=io_options) \n",
    "                elif solver_option == 1:\n",
    "\n",
    "                    opt = SolverFactory('cplex',executable = \"/home/gridsan/gnhe/opt/ibm/ILOG/CPLEX_Studio129/cplex/bin/x86-64_linux/cplex\")\n",
    "                    opt.options['timelimit'] = timelimit\n",
    "                    results = opt.solve(model,tee=print_log)\n",
    "                else:\n",
    "                    opt = SolverFactory('gurobi',executable=\"/usr/local/gurobi/gurobi951/linux64/bin/gurobi.sh\")\n",
    "                    opt.options['timelimit'] = timelimit\n",
    "#             opt.options['timelimit'] = 20\n",
    "                    results = opt.solve(model,tee=print_log)\n",
    "                                \n",
    "            except Exception as vehicle_energy:\n",
    "                success_flag = 0\n",
    "                if print_error == 1:\n",
    "                    print('Error:',vehicle_energy)\n",
    "                    print('RetrinG...')\n",
    "                time.sleep( 5 )\n",
    "\n",
    "\n",
    "        real_profit = model.profit.value+model.cost_sto.value\n",
    "        sta_profit.append(model.profit.value+model.cost_sto.value)\n",
    "        sta_usage.append(model.usage.value)\n",
    "        sta_reserve_rev.append(model.reserve_revenue.value)    \n",
    "\n",
    "        elapsed_time = time.time() - start_time  \n",
    "        elapsed_time2.append(elapsed_time)\n",
    "\n",
    "\n",
    "        print('Task ID:', str(c_index), round(mcu,3), 'Year:',year_num, 'Day:',day, 'Profit:',round(real_profit), 'Elapsed_time',elapsed_time)\n",
    "    \n",
    "    if len(day_set) != 1:\n",
    "        for i in range(len(elapsed_time2)-1):\n",
    "            elapsed_time2[i+1] = elapsed_time2[i+1] + elapsed_time2[i]\n",
    "    \n",
    "    if rep_log == 0:\n",
    "        return(model,sta_profit,sta_usage,sta_reserve_rev,elapsed_time2,G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
